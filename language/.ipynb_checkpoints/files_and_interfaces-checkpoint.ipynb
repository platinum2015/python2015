{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Contents \n",
    "- [file](#file) \n",
    "- [CSV or  char separated](#csv) ' ' [json](#json)' ' [xml](#xml) ' '[excel](#excel) ' ' [pickle](#pickle)\n",
    "- [webservice](#webservice) ' ' [urllib](#urllib)\n",
    "- [standardoutput](#standardoutput)\n",
    "- [h t m l ](#hz)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"file\"></a>\n",
    "<hr>\n",
    "# File\n",
    " - http://www.tutorialspoint.com/python/python_files_io.htm\n",
    " Nei Path doppio slash... \\t windows is a tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#open mode r w a r+ w+ a+\n",
    "filename = 'D:/datasets/numpyload.txt'\n",
    "txt_ref = open(filename)\n",
    "print \"READ------\"\n",
    "print txt_ref.read()\n",
    "# print txt_ref.read(100) read 100 byte max\n",
    "print \"after full read pointer is at the end\" ,txt_ref.readline()\n",
    "txt_ref.seek(0)\n",
    "print \"reset pointer and read again \" ,txt_ref.readline()\n",
    "print txt_ref.readline()\n",
    "txt_ref.close()\n",
    "print \"READLINE------ read next roW : Note read \"\n",
    "txt_ref = open(filename)\n",
    "print txt_ref.readline()\n",
    "print txt_ref.readline()\n",
    "txt_ref.close()\n",
    "print \"READLINE_S ------ read next 2bytes : Note read \"\n",
    "txt_ref = open(filename)\n",
    "print txt_ref.readline(2)\n",
    "print txt_ref.readline(2)\n",
    "txt_ref.close()\n",
    "\n",
    "print \"WRITE ------\"\n",
    "filename_wr = 'D:/datasets/write_test.txt'\n",
    "target = open(filename_wr, 'w')\n",
    "target.write('test \\n')\n",
    "target.close()\n",
    "print \"was written %r:\" % open(filename_wr).read()\n",
    "target.close()\n",
    "print \"TRUNCATE ------\"\n",
    "target = open(filename_wr, 'w+')\n",
    "target.truncate()\n",
    "print \"after truncate\" \n",
    "print target.read()\n",
    "target.close()\n",
    "print \"EXISTS ------\"\n",
    "from os.path import exists\n",
    "#https://docs.python.org/2/library/os.path.html\n",
    "print \"%s  exists?  %r\"  % ( filename , exists(filename)  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FILE Looping pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read with error handling\n"
     ]
    }
   ],
   "source": [
    "print \"Read with error handling\"\n",
    "try:\n",
    "    f = open(\"does_not_exist.txt\", 'r')\n",
    "except IOError, detail:\n",
    "    print \"Cannot open file \"+\"does_not_exist.txt\", detail\n",
    "else:\n",
    "    with f:        \n",
    "        print\"notice the comma, if ommited, there is an empty line\"\n",
    "        for line in f:\n",
    "        # for index,line in enumerate(f):    \n",
    "            print line, \n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\python2015\\language\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "#os.path.join(<my_directory>, <my_sub_directory>)\n",
    "#os.path.abspath(<a_relative_path>)\n",
    "#path_to_file = os.path.abspath(os.path.join(os.getcwd(), '..', 'test.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"csv\"></a>\n",
    "<hr>\n",
    "## CSV or  char separated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n",
      "Int64Index([0, 1, 2], dtype='int64')\n",
      "Index([u'a', u'b', u'c', u'd', u'message'], dtype='object')\n",
      "[[1L 2L 3L 4L 'hello']\n",
      " [5L 6L 7L 8L 'world']\n",
      " [9L 10L 11L 12L 'foo']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td>  2</td>\n",
       "      <td>  3</td>\n",
       "      <td>  4</td>\n",
       "      <td> hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 5</td>\n",
       "      <td>  6</td>\n",
       "      <td>  7</td>\n",
       "      <td>  8</td>\n",
       "      <td> world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 9</td>\n",
       "      <td> 10</td>\n",
       "      <td> 11</td>\n",
       "      <td> 12</td>\n",
       "      <td>   foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#READ CSV   (with header)\n",
    "df = pd.read_csv('H:/Technology/python/Dataset/pydata-book-master/ch06/ex1.csv')\n",
    "print( df )\n",
    "print( df.index )\n",
    "print( df.columns )\n",
    "print( df.values )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   1   2   3      4\n",
      "0  1   2   3   4  hello\n",
      "1  5   6   7   8  world\n",
      "2  9  10  11  12    foo\n",
      "   col_1  col_2  col_3  col_4  testo\n",
      "0      1      2      3      4  hello\n",
      "1      5      6      7      8  world\n",
      "2      9     10     11     12    foo\n"
     ]
    }
   ],
   "source": [
    "#READ CSV   (withOUT header)\n",
    "df = pd.read_csv('H:/Technology/python/Dataset/pydata-book-master/ch06/ex2.csv' , header=None)\n",
    "print(df)\n",
    "#with explicit cols\n",
    "df=pd.read_csv('H:/Technology/python/Dataset/pydata-book-master/ch06/ex2.csv', names=['col_1', 'col_2', 'col_3', 'col_4', 'testo'])\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td>  2</td>\n",
       "      <td>  3</td>\n",
       "      <td>  4</td>\n",
       "      <td> hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 5</td>\n",
       "      <td>  6</td>\n",
       "      <td>  7</td>\n",
       "      <td>  8</td>\n",
       "      <td> world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 9</td>\n",
       "      <td> 10</td>\n",
       "      <td> 11</td>\n",
       "      <td> 12</td>\n",
       "      <td>   foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#READ TABLE\n",
    "tab=pd.read_table('H:/Technology/python/Dataset/pydata-book-master/ch06/ex1.csv', sep=',')\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to csv\n"
     ]
    }
   ],
   "source": [
    "#WRITE to CSV \n",
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],#Column 1\n",
    "        'year': [2000, 2001, 2002, 2001, 2002],#Column 2\n",
    "        'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}#Column 3\n",
    "frame = pd.DataFrame(data)\n",
    "print(\"to csv\")\n",
    "frame.to_csv('H:/Technology/python/Dataset/out_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#READ / WRITE TEXT    (Text --->  Dataframe)\n",
    "'''\n",
    "read_csv\n",
    "    Load delimited data from a file, URL, or file-like object. Use comma as default delimiter\n",
    "read_table\n",
    "    Load delimited data from a file, URL, or file-like object. Use tab ('\\t') as default delimiter\n",
    "read_fwf\n",
    "    Read data in fixed-width column format (that is, no delimiters)\n",
    "read_clipboard\n",
    "    Version of read_table that reads data from the clipboard. Useful for converting tables from web pages\n",
    "\n",
    "Type inference\n",
    "'''\n",
    "#Missing values (Values empty or marked with SENTINEL)\n",
    "#Common SENTINEL: NA  /    -1.    /   #IND  /    NULL\n",
    "pd.isnull(result)#0 False False False False False True\n",
    "result = pd.read_csv('ch06/ex5.csv', na_values=['NULL'])#0 one 1 2 3 4 NaN\n",
    "sentinels = {'message': ['foo', 'NA'], 'something': ['two']}#with sentinels\n",
    "pd.read_csv('ch06/ex5.csv', na_values=sentinels)\n",
    "#property\n",
    "path #String indicating filesystem location, URL, or file-like object\n",
    "sep or delimiter #Character sequence or regular expression to use to split fields in each row\n",
    "header #Row number to use as column names. Defaults to 0 (first row), but should be None if there is no headerrow\n",
    "index_col #Column numbers or names to use as the row index in the result. Can be a single name/number or a list\n",
    "    #   of them for a hierarchical index\n",
    "names #List of column names for result, combine with header=None\n",
    "skiprows #Number of rows at beginning of file to ignore or list of row numbers (starting from 0) to skip\n",
    "na_values #Sequence of values to replace with NA\n",
    "comment #Character or characters to split comments off the end of lines\n",
    "parse_dates #Attempt to parse data to datetime; False by default. If True, will attempt to parse all columns. Otherwise\n",
    "    #can specify a list of column numbers or name to parse. If element of list is tuple or list, will combine\n",
    "    #multiple columns together and parse to date (for example if date/time split across two columns)\n",
    "keep_date_col #If joining columns to parse date, drop the joined columns. Default True\n",
    "converters #Dict containing column number of name mapping to functions. For example {'foo': f} would apply\n",
    "    #the function f to all values in the 'foo' column\n",
    "    #dayfirst When parsing potentially ambiguous dates, treat as international format (e.g. 7/6/2012 -> June 7,\n",
    "    #2012). Default False\n",
    "date_parser #Function to use to parse datesnrows Number of rows to read from beginning of file\n",
    "iterator #Return a TextParser object for reading file piecemeal\n",
    "chunksize #For iteration, size of file chunks\n",
    "skip_footer #Number of lines to ignore at end of file\n",
    "    #verbose Print various parser output information, like the number of missing values placed in non-numericcolumns\n",
    "encoding #Text encoding for unicode. For example 'utf-8' for UTF-8 encoded text\n",
    "squeeze #If the parsed data only contains one column return a Series\n",
    "thousands #Separator for thousands, e.g. ',' or '.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name;surname;salary;']\n",
      "['john;smith;100']\n",
      "['marc;twin;110']\n",
      "['alex;johnson;120']\n",
      "list version\n",
      "header\n",
      "['name;surname;salary;']\n",
      "values\n",
      "[['john;smith;100'], ['marc;twin;110'], ['alex;johnson;120']]\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 22] invalid mode ('w') or filename: 'H:\\\\Technology\\\\python\\\\Dataset\\test_out.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-b6ef3f784923>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#WRITE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mfileout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'H:\\Technology\\python\\Dataset\\test_out.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m: [Errno 22] invalid mode ('w') or filename: 'H:\\\\Technology\\\\python\\\\Dataset\\test_out.csv'"
     ]
    }
   ],
   "source": [
    "#Manual tasks \n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "d='C:\\\\workspace\\\\ZVVS\\\\00_SOSAuftraege\\\\SOS\\\\243739\\\\'\n",
    "file_csv = os.path.join(d, 'VW_ad_tstat_20151103.csv') \n",
    "print \"---- WITH HEADER \"\n",
    "with open(d+file_csv, 'rb') as f:\n",
    "    reader = csv.reader(f, delimiter=';')\n",
    "    for row in reader:\n",
    "        #date = row[0]\n",
    "        #symbol = row[1]\n",
    "        #closing_price = float(row[2])\n",
    "        #process(date, symbol, closing_price)\n",
    "        print  row\n",
    "        \n",
    "\n",
    "print \"---- WITHOUT HEADER \"\n",
    "with open(d+file_csv, 'rb') as f:\n",
    "    reader = csv.DictReader(f, delimiter=';')\n",
    "    c = 0\n",
    "    for row in reader:\n",
    "        if c == 0:\n",
    "            c = 1            \n",
    "        else:\n",
    "            #date = row[\"date\"]\n",
    "            #symbol = row[\"symbol\"]\n",
    "           #closing_price = float(row[\"closing_price\"])\n",
    "           # process(date, symbol, closing_price)\n",
    "            print row\n",
    "            break\n",
    "import csv\n",
    "with open('tab_delimited_stock_prices.txt', 'rb') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        date = row[0]\n",
    "        symbol = row[1]\n",
    "        closing_price = float(row[2])\n",
    "         process(date, symbol, closing_price)\n",
    "\n",
    "print('list version')\n",
    "lines  = list(csv.reader(open(r'H:\\Technology\\python\\Dataset\\test_csv.csv')))\n",
    "header = lines[0]\n",
    "values = lines[1:]\n",
    "print(\"header\")\n",
    "print( header )\n",
    "print(\"values\")\n",
    "print( values  )\n",
    "\n",
    "\n",
    "#WRITE\n",
    "fileout=open('H:\\Technology\\python\\Dataset\\test_out.csv','w') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#WRITE\n",
    "with open('H:\\Technology\\python\\Dataset\\out.csv','wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow('aaaaaa')\n",
    "    writer.writerow('bbbbbb')\n",
    "    writer.writerow('cccccc')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "delimiter One-character string to separate fields. Defaults to ','.\n",
    "lineterminator Line terminator for writing, defaults to '\\r\\n'. Reader ignores this and recognizes\n",
    "cross-platform line terminators.\n",
    "quotechar Quote character for fields with special characters (like a delimiter). Default is '\"'.\n",
    "quoting Quoting convention. Options include csv.QUOTE_ALL (quote all fields),\n",
    "csv.QUOTE_MINIMAL (only fields with special characters like the delimiter),\n",
    "csv.QUOTE_NONNUMERIC, and csv.QUOTE_NON (no quoting). See Python’s\n",
    "documentation for full details. Defaults to QUOTE_MINIMAL.\n",
    "skipinitialspace Ignore whitespace after each delimiter. Default False.\n",
    "doublequote How to handle quoting character inside a field. If True, it is doubled. See online\n",
    "documentation for full detail and behavior.\n",
    "escapechar String to escape\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"standardoutput\"></a>\n",
    "<hr>\n",
    "## TO STANDARD OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TO STANDARD OUTPUT  with SEP\n",
      "|pop|state|year\n",
      "0|1.5|Ohio|2000\n",
      "1|1.7|Ohio|2001\n",
      "2|3.6|Ohio|2002\n",
      "3|2.4|Nevada|2001\n",
      "4|2.9|Nevada|2002\n",
      "TO STANDARD OUTPUT  without HEADER \n",
      "1.5,Ohio,2000\n",
      "1.7,Ohio,2001\n",
      "3.6,Ohio,2002\n",
      "2.4,Nevada,2001\n",
      "2.9,Nevada,2002\n"
     ]
    }
   ],
   "source": [
    "#WRITE TO STANDARD OUTPUT\n",
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],#Column 1\n",
    "        'year': [2000, 2001, 2002, 2001, 2002],#Column 2\n",
    "        'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}#Column 3\n",
    "frame = pd.DataFrame(data)\n",
    "print(\"TO STANDARD OUTPUT  with SEP\")\n",
    "frame.to_csv(sys.stdout, sep='|')\n",
    "print(\"TO STANDARD OUTPUT  without HEADER \")\n",
    "frame.to_csv(sys.stdout, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"excel\"></a>\n",
    "<hr>\n",
    "## Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "Location = r'C:\\workspace\\ZVVS\\01_EntwicklungsBackground\\Check_Betrieb\\status_kontrolle_fremdprod\\18112014_status.xls'\n",
    "xls_file = pd.ExcelFile(Location)\n",
    "table = xls_file.parse('18112014_status')\n",
    "table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#v01_plotting_excel_grades.py\n",
    "from pylab import *\n",
    "import xlrd\n",
    "\n",
    "#wb = xlrd.open_workbook('D:\\workspace\\cas_infe\\01_Scripting\\v01_grades.xls')\n",
    "wb = xlrd.open_workbook('D:/workspace/cas_infe/01_Scripting/v01_grades.xls')\n",
    "\n",
    "sheet = wb.sheet_by_index(0)\n",
    "\n",
    "grades = []\n",
    "for i in range(sheet.nrows):\n",
    "    grades.append(float(sheet.cell(i,0).value))\n",
    "\n",
    "hist(grades, bins=30)\n",
    "xlim([1,6])\n",
    "xlabel('Grade')\n",
    "ylabel('Number of students')\n",
    "title('Exam - Grades')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#FILE\n",
    "#################################################################################\n",
    "test_file = open(\"aypaaypa\",\"wb\")\n",
    "print(test_file.mode)\n",
    "test_file.write(\"ciao \\n\")\n",
    "test_file.close()\n",
    "test_file = open(\"test.txt\",\"r\")\n",
    "lines = test_file.readlines()\n",
    "print lines\n",
    "print len(lines)\n",
    "test_file.close()\n",
    "\n",
    "\n",
    "\n",
    "# CSV  C S V\n",
    "import csv\n",
    "#READ\n",
    "f = open('ch06/ex7.csv')\n",
    "reader = csv.reader(f)\n",
    "for line in reader:\n",
    "    print line\n",
    "\n",
    "lines = list(csv.reader(open('ch06/ex7.csv')))\n",
    "header, values = lines[0], lines[1:]\n",
    "data_dict = {h: v for h, v in zip(header, zip(*values))}\n",
    "data_dict#Out[897]: {'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')}\n",
    "\n",
    "#dialect\n",
    "class my_dialect(csv.Dialect):\n",
    "lineterminator = '\\n'\n",
    "delimiter = ';'\n",
    "quotechar = '\"'\n",
    "#WRITE\n",
    "with open('mydata.csv', 'w') as f:\n",
    "writer = csv.writer(f, dialect=my_dialect)\n",
    "writer.writerow(('one', 'two', 'three'))\n",
    "writer.writerow(('1', '2', '3'))\n",
    "writer.writerow(('4', '5', '6'))\n",
    "writer.writerow(('7', '8', '9'))\n",
    "\n",
    "#JSON\n",
    "import json\n",
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    "\"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n",
    "\"pet\": null,\n",
    "\"siblings\": [{\"name\": \"Scott\", \"age\": 25, \"pet\": \"Zuko\"},\n",
    "{\"name\": \"Katie\", \"age\": 33, \"pet\": \"Cisco\"}]\n",
    "}\n",
    "\"\"\"\n",
    "result = json.loads(obj)\n",
    "result\n",
    "#options: call (buy) put (sell)  at price (strike) expiry (data della transazione)\n",
    "from lxml.html import parse\n",
    "from urllib2 import urlopen\n",
    "parsed = parse(urlopen('http://finance.yahoo.com/q/op?s=AAPL+Options'))\n",
    "doc = parsed.getroot()\n",
    "links = doc.findall('.//a')\n",
    "links[15:20]\n",
    "lnk = links[28]\n",
    "lnk\n",
    "lnk.get('href')\n",
    "lnk.text_content()\n",
    "urls = [lnk.get('href') for lnk in doc.findall('.//a')]\n",
    "urls[-10:]\n",
    "tables = doc.findall('.//table')\n",
    "calls = tables[9]\n",
    "puts = tables[13]\n",
    "rows = calls.findall('.//tr')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"urllib\"></a>\n",
    "### I/O from the web – urllib\n",
    " - https://docs.python.org/2/library/urllib.html\n",
    " - http://docs.python-requests.org/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"webservice\"></a>\n",
    "<hr>\n",
    "# WEB SERVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What city would you like to know about? london\n",
      "http://api.openweathermap.org/data/2.5/weather?q=london&units=metric&APPID=77028127b3488cd86df47953d28bd086\n",
      "It is 13.2 degrees in london\n",
      "The weather can be described as \"light intensity drizzle\".\n"
     ]
    }
   ],
   "source": [
    "import urllib,json\n",
    "city_name= raw_input(\"What city would you like to know about? \")\n",
    "API_key= \"77028127b3488cd86df47953d28bd086\"\n",
    "x= (urllib.quote(city_name), API_key)\n",
    "api_url= \"http://api.openweathermap.org/data/2.5/weather?q=%s&units=metric&APPID=%s\" % (urllib.quote(city_name), API_key)\n",
    "\n",
    "try: \n",
    "    print(api_url)\n",
    "    response = urllib.urlopen(api_url)\n",
    "    json_tree= json.loads(response.read())\n",
    "\n",
    "    if json_tree['cod'] == 200:\n",
    "        temperature = json_tree[\"main\"][\"temp\"]\n",
    "        description = json_tree[\"weather\"][0][\"description\"]\n",
    "    \n",
    "        print \"It is \" + str(temperature) +  \" degrees in \" + city_name\n",
    "        print \"The weather can be described as \\\"\" + description + \"\\\".\"\n",
    "    else:\n",
    "        print \"The service doesn't know that city.\"\n",
    "except Exception:\n",
    "    print \"Couldn't connect to the openweathermapservice.\"\n",
    "\"\"\"\n",
    "{\n",
    "\"coord\":\n",
    "     {\"lon\":6.63,\"lat\":46.52},\n",
    "\"weather\":[\n",
    "          {\"id\":802,\"main\":\"Clouds\",\"description\":\"scattered clouds\",\"icon\":\"03d\"}\n",
    "          ],\n",
    "\"base\":\"stations\",\n",
    "\"main\":\n",
    "    {\"temp\":10.23,\"pressure\":1018,\"humidity\":62,\"temp_min\":6,\"temp_max\":13},\n",
    "\"visibility\":10000,\n",
    "\"wind\":    {\"speed\":5.1,\"deg\":60},\n",
    "\"clouds\":{\"all\":40},\n",
    "\"dt\":1445266200,\n",
    " \"sys\":\n",
    "        {\"type\":1,\"id\":6010,\"message\":0.0107,\"country\":\"CH\",\"sunrise\":1445234204,\"sunset\":1445272757},\n",
    "\"id\":2659994,\n",
    "\"name\":\"Lausanne\",\n",
    "\"cod\":200\n",
    " }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'instance'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (type(response))  \n",
    "print (response.read())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " <a id=\"json\"></a>\n",
    "<hr>\n",
    "# JSON\n",
    "JSON : https://docs.python.org/2/library/json.html\n",
    "UNICODE : https://docs.python.org/2/howto/unicode.html\n",
    "\n",
    " - JSON---------->Python\n",
    " - object{ }---------->dict\n",
    " - array [ ]---------->list\n",
    " - string---------->string,unicode\n",
    " - number---------->int, long,float\n",
    " - true---------->True\n",
    " - false---------->False\n",
    " - null---------->None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----SERIALIZE (as JSONformattedstream) / ENCODING : DUMPx\n",
      "[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}]\n",
      "\"\\\"foo\\bar\"\n",
      "Serialize to FILE:TODO!!!!!!!!!!!!!!!!\n",
      "-----DESERIALIZE / DECODING : LOADx\n",
      "[u'foo', {u'bar': [u'baz', None, 1.0, 2]}]\n",
      "\"foo\bar\n",
      "DeSerialize from FILE:TODO!!!!!!!!!!!!!!!!\n",
      "\"foo\bar\n",
      "-----ENCODE\n",
      "-----DECODE\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(\"-----SERIALIZE (as JSONformattedstream) / ENCODING : DUMPx\")\n",
    "print json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])\n",
    "print json.dumps(\"\\\"foo\\bar\")\n",
    "print(\"Serialize to FILE:TODO!!!!!!!!!!!!!!!!\")\n",
    "a_filename = 'test.txt'\n",
    "f = open(a_filename, 'w')\n",
    "json.dump(\"\\\"foo\\bar\",f)\n",
    "f.close()\n",
    "print(\"-----DESERIALIZE / DECODING : LOADx\")\n",
    "print(json.loads('[\"foo\", {\"bar\":[\"baz\", null, 1.0, 2]}]'))\n",
    "print(json.loads('\"\\\\\"foo\\\\bar\"'))\n",
    "print(\"DeSerialize from FILE:TODO!!!!!!!!!!!!!!!!\")\n",
    "f = open(a_filename, 'r')\n",
    "o=json.load(f)\n",
    "f.close()\n",
    "\n",
    "print(o)\n",
    "print(\"-----ENCODE\")\n",
    "#print(json.JSONEncoder().encode(['foo', {'bar': ('baz', None, 1.0, 2)}]))\n",
    "#print(json.JSONEncoder().encode((\"\\\"foo\\bar\")))\n",
    "print(\"-----DECODE\")\n",
    "#print(json.JSONEncoder().decode(\"[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}])\")\n",
    "#raw_decode(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n",
      "\n",
      "{\n",
      "    \"Name\": \"McGregor\",\n",
      "    \"Firstname\": \"John\",\n",
      "    \"Points\": [100, 90, 85]\n",
      "}\n",
      "\n",
      "\n",
      "<type 'dict'>\n",
      "{u'Points': [100, 90, 85], u'Name': u'McGregor', u'Firstname': u'John'}\n",
      "{'Points': [100, 90, 85], 'Name': 'McGregor', 'Firstname': 'John'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def convert(input):\n",
    "    if isinstance(input, dict):\n",
    "        return {convert(key): convert(value) for key, value in input.iteritems()}\n",
    "    elif isinstance(input, list):\n",
    "        return [convert(element) for element in input]\n",
    "    elif isinstance(input, unicode):\n",
    "        return input.encode('utf-8')\n",
    "    else:\n",
    "        return input\n",
    "\n",
    "\n",
    "json_as_text = '''\n",
    "{\n",
    "    \"Name\": \"McGregor\",\n",
    "    \"Firstname\": \"John\",\n",
    "    \"Points\": [100, 90, 85]\n",
    "}\n",
    "\n",
    "'''\n",
    "print type(json_as_text)\n",
    "print json_as_text\n",
    "\n",
    "info = json.loads(json_as_text)\n",
    "print type(info)\n",
    "print info\n",
    "print convert(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path at terminal when executing this file\n",
      "D:\\workspace\\python2015\\language\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Path at terminal when executing this file\")\n",
    "print(os.getcwd() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'pet': None, u'siblings': [{u'pet': u'Zuko', u'age': 25, u'name': u'Scott'}, {u'pet': u'Cisco', u'age': 33, u'name': u'Katie'}], u'name': u'Wes', u'places_lived': [u'United States', u'Spain', u'Germany']}\n",
      "dump to string\n",
      "{\n",
      " \"name\" --> \"Wes\";\n",
      " \"pet\" --> null;\n",
      " \"places_lived\" --> [\n",
      "  \"United States\";\n",
      "  \"Spain\";\n",
      "  \"Germany\"\n",
      " ];\n",
      " \"siblings\" --> [\n",
      "  {\n",
      "   \"age\" --> 25;\n",
      "   \"name\" --> \"Scott\";\n",
      "   \"pet\" --> \"Zuko\"\n",
      "  };\n",
      "  {\n",
      "   \"age\" --> 33;\n",
      "   \"name\" --> \"Katie\";\n",
      "   \"pet\" --> \"Cisco\"\n",
      "  }\n",
      " ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    "\"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n",
    "\"pet\": null,\n",
    "\"siblings\": [\n",
    "              {\"name\": \"Scott\", \"age\": 25, \"pet\": \"Zuko\"},\n",
    "              {\"name\": \"Katie\", \"age\": 33, \"pet\": \"Cisco\"}\n",
    "            ]\n",
    "}\n",
    "\"\"\"\n",
    "result = json.loads(obj)\n",
    "print(result)\n",
    "print(\"dump to string\")\n",
    "print(json.dumps(result, indent=1, separators=(';', ' --> '),sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"xml\"></a>\n",
    "<hr>\n",
    "# XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml.html import parse\n",
    "Location = r'C:\\app\\Finance.html' #parsed = parse(urlopen('http://finance.yahoo.com/q/op?s=AAPL+Options'))\n",
    "doc = open(Location,\"r\")\n",
    "parsed=parse(doc)\n",
    "doc = parsed.getroot()#HTML root\n",
    "#FIND the <a> links\n",
    "links = doc.findall('.//a')\n",
    "\n",
    "for lnk in links:\n",
    "    print(lnk.text_content())\n",
    " \n",
    "'''\n",
    "links[15:20]\n",
    "lnk = links[28]\n",
    "lnk\n",
    "\n",
    "lnk.get('href')#https://autos.yahoo.com/;_ylt=AwrBxMH4.jhVzm8AJQB.FJF4\n",
    "\n",
    "lnk.text_content()\n",
    "urls = [lnk.get('href') for lnk in doc.findall('.//a')]\n",
    "urls[-10:]\n",
    "tables = doc.findall('.//table')\n",
    "doc\n",
    "#calls = tables[9]\n",
    "#puts = tables[13]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pickle\"></a>\n",
    "###PICKLE\n",
    " - http://deeplearning.net/software/theano/tutorial/loading_and_saving.html\n",
    "Can be used if you want to dump your structure duringa  days long data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import os\n",
    "print os.getcwd()\n",
    "a_dict = {\"Jess\":\"079 778 4565\",\"Pete\":\"079 123 1234\"}\n",
    "a_list = [\"Hello\", \"World\", \"!\"]\n",
    "print(\"----- PICKLE\")\n",
    "pickle_file = open('test.pkl','wb') #open to write binary\n",
    "cPickle.dump(a_dict, pickle_file, cPickle.HIGHEST_PROTOCOL)\n",
    "cPickle.dump(a_list, pickle_file, cPickle.HIGHEST_PROTOCOL)\n",
    "pickle_file.close()\n",
    "print(\"----- UNPICKLE\")\n",
    "pickle_file = open('test.pkl','rb') #open to read binary\n",
    "a_dict_loaded = cPickle.load(pickle_file) # same load sequence as dump\n",
    "a_list_loaded = cPickle.load(pickle_file)\n",
    "pickle_file.close()\n",
    "\n",
    "print a_dict, a_list\n",
    "print 'Pickled and unpickled to get:'\n",
    "print a_dict_loaded, a_list_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "print(cPickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"ht\"></a>\n",
    "##HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', error(10060, 'Ein Verbindungsversuch ist fehlgeschlagen, da die Gegenstelle nach einer bestimmten Zeitspanne nicht richtig reagiert hat, oder die hergestellte Verbindung war fehlerhaft, da der verbundene Host nicht reagiert hat'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bf07f9e1977e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http://www.google.com\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html5lib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\p155121\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\requests\\api.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\p155121\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\requests\\api.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;31m# By explicitly closing the session, we avoid leaving sockets open which\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m# can trigger a ResourceWarning in some cases, and look like a memory leak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\p155121\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\requests\\sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    463\u001b[0m         }\n\u001b[0;32m    464\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\p155121\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\requests\\sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\p155121\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\requests\\adapters.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', error(10060, 'Ein Verbindungsversuch ist fehlgeschlagen, da die Gegenstelle nach einer bestimmten Zeitspanne nicht richtig reagiert hat, oder die hergestellte Verbindung war fehlerhaft, da der verbundene Host nicht reagiert hat'))"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "html = requests.get(\"http://www.google.com\").text\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "print soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
